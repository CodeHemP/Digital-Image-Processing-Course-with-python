{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETECCION DE OBJETOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECCION DE ROSTROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    " \n",
    "face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml') \n",
    " \n",
    "cap = cv2.VideoCapture(1) \n",
    "scaling_factor = 1 \n",
    " \n",
    "while True: \n",
    "    ret, frame = cap.read() \n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    " \n",
    "    face_rects = face_cascade.detectMultiScale(frame) \n",
    "    for (x,y,w,h) in face_rects: \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3) \n",
    " \n",
    "    cv2.imshow('Face Detector', frame) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECCION DE OJOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    " \n",
    "face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_eye.xml') \n",
    "cap = cv2.VideoCapture(0) \n",
    "ds_factor = 1\n",
    " \n",
    "while True: \n",
    "    ret, frame = cap.read() \n",
    "    frame = cv2.resize(frame, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_AREA) \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    " \n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    for (x,y,w,h) in faces: \n",
    "        roi_gray = gray[y:y+h, x:x+w] \n",
    "        roi_color = frame[y:y+h, x:x+w] \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray) \n",
    "        if(len(eyes)!=2):\n",
    "            continue\n",
    "        for (x_eye,y_eye,w_eye,h_eye) in eyes: \n",
    "            center = (int(x_eye + 0.5*w_eye), int(y_eye + 0.5*h_eye)) \n",
    "            radius = int(0.3 * (w_eye + h_eye)) \n",
    "            color = (0, 255, 0) \n",
    "            thickness = 3 \n",
    "            cv2.circle(roi_color, center, radius, color, thickness) \n",
    " \n",
    "    cv2.imshow('Eye Detector', frame) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFECTOS TIKTOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "0.22304166666666667 101\n",
      "0.22304166666666667 101\n",
      "0.22083333333333333 100\n",
      "0.205375 93\n",
      "0.18329166666666669 83\n",
      "0.18550000000000003 84\n",
      "0.192125 87\n",
      "0.18329166666666669 83\n",
      "0.17445833333333335 79\n",
      "Eyes not detected\n",
      "0.16783333333333333 76\n",
      "0.16783333333333333 76\n",
      "0.165625 75\n",
      "0.16783333333333333 76\n",
      "0.16783333333333333 76\n",
      "Eyes not detected\n",
      "0.17004166666666667 77\n",
      "0.178875 81\n",
      "0.178875 81\n",
      "0.18329166666666669 83\n",
      "0.18108333333333335 82\n",
      "0.18108333333333335 82\n",
      "Eyes not detected\n",
      "0.178875 81\n",
      "Eyes not detected\n",
      "0.18108333333333335 82\n",
      "0.178875 81\n",
      "0.178875 81\n",
      "0.18991666666666668 86\n",
      "0.18108333333333335 82\n",
      "0.18108333333333335 82\n",
      "0.18770833333333334 85\n",
      "0.18550000000000003 84\n",
      "0.18550000000000003 84\n",
      "0.18770833333333334 85\n",
      "0.20095833333333335 91\n",
      "0.20095833333333335 91\n",
      "Eyes not detected\n",
      "0.23187500000000003 105\n",
      "Eyes not detected\n",
      "0.21420833333333336 97\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "0.20095833333333335 91\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "0.19433333333333333 88\n",
      "Eyes not detected\n",
      "0.192125 87\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "Eyes not detected\n",
      "0.192125 87\n",
      "0.19433333333333333 88\n",
      "0.18991666666666668 86\n",
      "0.192125 87\n",
      "0.19433333333333333 88\n",
      "0.19654166666666667 89\n",
      "0.19654166666666667 89\n",
      "0.192125 87\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    " \n",
    "face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_eye.xml') \n",
    "cap = cv2.VideoCapture(1)\n",
    "sunglasses_img = cv2.imread('images/sunglasses.png')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() \n",
    "    frame = cv2.resize(frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    vh, vw = frame.shape[:2]\n",
    "    vh, vw = int(vh), int(vw)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=1)\n",
    "    centers = []\n",
    "\n",
    "    for (x,y,w,h) in faces: \n",
    "        roi_gray = gray[y:y+h, x:x+w] \n",
    "        roi_color = frame[y:y+h, x:x+w] \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray) \n",
    "        if(len(eyes)!=2):\n",
    "            continue\n",
    "        for (x_eye,y_eye,w_eye,h_eye) in eyes: \n",
    "            centers.append((x + int(x_eye + 0.5*w_eye), y + int(0.75*h_eye))) \n",
    "    \n",
    "    if len(centers) > 1: # if detects both eyes\n",
    "        h, w = sunglasses_img.shape[:2]\n",
    "        # Extract the region of interest from the image \n",
    "        eye_distance = abs(centers[1][0] - centers[0][0])\n",
    "        # Overlay sunglasses; the factor 2.12 is customizable depending on the size of the face \n",
    "        sunglasses_width = 2.12 * eye_distance\n",
    "        scaling_factor = sunglasses_width / w\n",
    "        print(scaling_factor, eye_distance)\n",
    "        overlay_sunglasses = cv2.resize(sunglasses_img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        x = centers[0][0] if centers[0][0] < centers[1][0] else centers[1][0] \n",
    "        y = centers[0][1] if centers[0][0] < centers[1][0] else centers[1][1] \n",
    "     \n",
    "        # customizable X and Y locations; depends on the size of the face \n",
    "        x -= int(0.26*overlay_sunglasses.shape[1])\n",
    "        y += int(0.26*overlay_sunglasses.shape[0])\n",
    "        \n",
    "        h, w = overlay_sunglasses.shape[:2]\n",
    "        h, w = int(h), int(w)\n",
    "        frame_roi = frame[y:y+h, x:x+w]\n",
    "        # Convert color image to grayscale and threshold it \n",
    "        gray_overlay_sunglassess = cv2.cvtColor(overlay_sunglasses, cv2.COLOR_BGR2GRAY) \n",
    "        ret, mask = cv2.threshold(gray_overlay_sunglassess, 180, 255, cv2.THRESH_BINARY_INV) \n",
    "\n",
    "        # Create an inverse mask \n",
    "        mask_inv = cv2.bitwise_not(mask) \n",
    "\n",
    "        try:\n",
    "            # Use the mask to extract the face mask region of interest \n",
    "            masked_face = cv2.bitwise_and(overlay_sunglasses, overlay_sunglasses, mask=mask) \n",
    "            # Use the inverse mask to get the remaining part of the image \n",
    "            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv) \n",
    "        except cv2.error as e:\n",
    "            print('Ignoring arithmentic exceptions: '+ str(e))\n",
    "            #raise e\n",
    "\n",
    "        # add the two images to get the final output \n",
    "        frame[y:y+h, x:x+w] = cv2.add(masked_face, masked_frame)\n",
    "    else:\n",
    "        print('Eyes not detected')\n",
    "\n",
    "    \n",
    "    cv2.imshow('Eye Detector', frame) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
